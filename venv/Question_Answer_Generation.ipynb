{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f193939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-02-21 09:39:16 +05:30)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --quiet ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9720c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.3 s (started: 2022-02-21 09:39:16 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf913c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.2 s (started: 2022-02-21 09:39:31 +05:30)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-6-6\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-6-6\")\n",
    "\n",
    "to_tokenize = \"\"\"In a traditional world, most companies resolve support issues manually. In this approach, customers or employees request a ticket through e-mail, ITSM portal, or call. This ticket is picked by a Level 1 technician based on availability after a long wait. During this time, customer or employee is frustrated and often unproductive waiting for their issues to be resolved. If the Level 1 technician can not resolve the issue, it will be escalated to Level 2, and the cycle of wait time and explanation restarts, increasing loss in productivity and frustration. If the Level 2 technical cannot resolve, it goes to Level 3 and then to the Supervisor / Manager. This approach gives the most human touch possible. It is not productive and efficient in this current world where time is gold, and no one wants to wait even for a few minutes, and surprisingly, customers and employees have to wait for minutes, hours, or in few cases - even days.\"\"\"\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer,framework=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f6fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 5s (started: 2022-02-21 10:00:07 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(summarizer, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('model.pkl', 'rb'))\n",
    "pickled_model.predict(to_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a574e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.9 s (started: 2022-02-21 09:40:23 +05:30)\n"
     ]
    }
   ],
   "source": [
    "summarized = summarizer(to_tokenize, min_length=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd64af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' In a traditional world, most companies resolve support issues manually . In this approach, customers or employees request a ticket through e-mail, ITSM portal, or call . This ticket is picked by a Level 1 technician based on availability after a long wait . This approach gives the most human touch possible. It is not productive and efficient in this current world where time is gold,'}]\n",
      "time: 0 ns (started: 2022-02-21 09:40:34 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Print summarized text\n",
    "print(summarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747a8b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.67 s (started: 2022-02-21 09:40:34 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "#keyword extraction\n",
    "def multipartite_keyword(text):\n",
    "    out=[]\n",
    "    try:\n",
    "        # 1. create a MultipartiteRank extractor.\n",
    "        extractor = pke.unsupervised.MultipartiteRank()\n",
    "\n",
    "        # 2. load the content of the document.\n",
    "        extractor.load_document(text)\n",
    "\n",
    "        # 3. select the longest sequences of nouns and adjectives, that do\n",
    "        #    not contain punctuation marks or stopwords as candidates.\n",
    "        pos = {'NOUN', 'PROPN', 'ADJ'}\n",
    "        stoplist = list(string.punctuation)\n",
    "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "        stoplist += stopwords.words('english')\n",
    "        extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
    "\n",
    "        # 4. build the Multipartite graph and rank candidates using random walk,\n",
    "        #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
    "        #    threshold/method parameters.\n",
    "        extractor.candidate_weighting(alpha=1.1,\n",
    "                                      threshold=0.74,\n",
    "                                      method='average')\n",
    "\n",
    "        # 5. get the 10-highest scored candidates as keyphrases\n",
    "        keyphrases = extractor.get_n_best(n=10)\n",
    "\n",
    "        for val in keyphrases:\n",
    "            out.append(val[0])\n",
    "    except:\n",
    "        out = []\n",
    "        traceback.print_exc()\n",
    "\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1929cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-02-21 09:40:43 +05:30)\n"
     ]
    }
   ],
   "source": [
    "#sumary text sentence tokenization\n",
    "summary=summarized[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ece28cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 203 ms (started: 2022-02-21 09:40:43 +05:30)\n"
     ]
    }
   ],
   "source": [
    "#keyword mapping\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "\n",
    "def get_keywords(originaltext,summarytext):\n",
    "    keywords =  multipartite_keyword(originaltext)\n",
    "    print (\"keywords unsummarized: \",keywords)\n",
    "    keyword_processor = KeywordProcessor()\n",
    "    for keyword in keywords:\n",
    "        keyword_processor.add_keyword(keyword)\n",
    "\n",
    "    keywords_found = keyword_processor.extract_keywords(summarytext)\n",
    "    keywords_found = list(set(keywords_found))\n",
    "    print (\"keywords_found in summarized: \",keywords_found)\n",
    "\n",
    "    important_keywords =[]\n",
    "    for keyword in keywords:\n",
    "        if keyword in keywords_found:\n",
    "            important_keywords.append(keyword)\n",
    "\n",
    "    return important_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a49c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords unsummarized:  ['level', 'customers', 'time', 'employees', 'support issues', 'traditional world', 'approach', 'frustrated', 'productivity', 'technician']\n",
      "keywords_found in summarized:  ['approach', 'employees', 'support issues', 'traditional world', 'customers', 'technician', 'level', 'time']\n",
      "['level', 'customers', 'time', 'employees', 'support issues', 'traditional world', 'approach', 'technician']\n",
      "time: 1.64 s (started: 2022-02-21 09:40:43 +05:30)\n"
     ]
    }
   ],
   "source": [
    "imp_keywords = get_keywords(to_tokenize,summary)\n",
    "print (imp_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6440c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.3 s (started: 2022-02-21 09:40:45 +05:30)\n"
     ]
    }
   ],
   "source": [
    "#called pretrained question generator model\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_model = question_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d5cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 25s (started: 2022-02-21 10:13:30 +05:30)\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(question_model, open('que_generator.pkl', 'wb'))\n",
    "# pickled_model = pickle.load(open('que_generator.pkl', 'rb'))\n",
    "# pickled_model(to_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b73dc8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.8 s (started: 2022-02-21 10:17:08 +05:30)\n"
     ]
    }
   ],
   "source": [
    "qg_model = pickle.load(open('que_generator.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e9cf96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 188 ms (started: 2022-02-21 10:18:05 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def get_question(context,answer,model,tokenizer):\n",
    "    text = \"context: {} answer: {}\".format(context,answer)\n",
    "    encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "    outs = qg_model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  max_length=72)\n",
    "\n",
    "\n",
    "    dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "\n",
    "\n",
    "    Question = dec[0].replace(\"question:\",\"\")\n",
    "    Question= Question.strip()\n",
    "    return Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5061b4b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.9 s (started: 2022-02-21 10:18:20 +05:30)\n"
     ]
    }
   ],
   "source": [
    "ls=[]\n",
    "for answer in imp_keywords:\n",
    "    ques = get_question(summary,answer,question_model,question_tokenizer)\n",
    "    q=ques\n",
    "    a=answer.capitalize()\n",
    "    b=[q,a]\n",
    "    ls.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b4ff18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"What level of technician picks a customer's ticket?\", 'Level'],\n",
       " ['Who requests a ticket through e-mail, ITSM portal or call?', 'Customers'],\n",
       " ['In a modern world where what is gold?', 'Time'],\n",
       " ['Customers or what other group may request a ticket through e-mail, ITSM portal, or call?',\n",
       "  'Employees'],\n",
       " ['In a traditional world, most companies resolve what manually?',\n",
       "  'Support issues'],\n",
       " ['In what type of world do most companies resolve support issues manually?',\n",
       "  'Traditional world'],\n",
       " ['What approach gives the most human touch possible?', 'Approach'],\n",
       " ['What level 1 person picks up a customer support ticket?', 'Technician']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-02-21 09:47:46 +05:30)\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec76d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
